<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="eagga">
<title>eagga â€¢ eagga</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="eagga">
<meta property="og:description" content="eagga">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">eagga</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9999</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item">
  <a class="nav-link" href="../articles/eagga.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>eagga</h1>
            <h3 data-toc-skip class="subtitle">Get started</h3>
            
      
      
      <div class="d-none name"><code>eagga.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="intro">Intro<a class="anchor" aria-label="anchor" href="#intro"></a>
</h2>
<p>The <code>EAGGA</code> algorithm is a model-agnostic framework
designed to jointly optimize the predictive performance and
interpretability of supervised machine learning models for tabular data.
This algorithm incorporates three key measures of interpretability:
feature sparsity, interaction sparsity of features, and sparsity of
non-monotone feature effects.</p>
<p>By formulating the hyperparameter optimization process of a machine
learning algorithm as a multi-objective optimization problem,
<code>EAGGA</code> enables the generation of diverse models that strike
a balance between high performance and interpretability within a single
optimization run. Efficient optimization is achieved by expanding the
search space of the learning algorithm through the inclusion of feature
selection, interaction, and monotonicity constraints in the
hyperparameter search which are represented in the form of a
groupstructure.</p>
<p>The core concept behind <code>EAGGA</code> lies in identifying the
Pareto optimal set of groups of selected features that can interact
within a model, along with determining their optimal monotonicity
constraints and the optimal hyperparameters of the learning algorithm
itself.</p>
<p>This vignette is a gentle introduction to the core functionality of
the <code>eagga</code> package. For more details on the algorithm
itself, please see <span class="citation">Schneider, Bischl, and Thomas
(2023)</span>. Note that the <code>eagga</code> package heavily builds
upon the <code>mlr3</code> ecosystem. If you are not familiar with it,
we highly recommend to make yourself familiar with it, by for example
reading the following book: <a href="https://mlr3book.mlr-org.com/" class="external-link uri">https://mlr3book.mlr-org.com/</a></p>
<p>As a final comment: In the following, we will write
<code>EAGGA</code> to refer to the algorithm, whereas <code>eagga</code>
will refer to the software implementation, i.e., the R package this
vignette is introducing.</p>
</div>
<div class="section level2">
<h2 id="technical-preliminaries">Technical Preliminaries<a class="anchor" aria-label="anchor" href="#technical-preliminaries"></a>
</h2>
<div class="section level3">
<h3 id="supported-learners">Supported Learners<a class="anchor" aria-label="anchor" href="#supported-learners"></a>
</h3>
<p>Although formulated model-agnostic, the current <code>EAGGA</code>
implementation currently only supports <code>XGBoost</code> learners (<a href="https://mlr3learners.mlr-org.com/reference/LearnerClassifXgboost.html" class="external-link"><code>LearnerClassifXgboost</code></a>
or <a href="https://mlr3learners.mlr-org.com/reference/LearnerRegrXgboost.html" class="external-link"><code>mlr3learners::LearnerRegrXgboost</code></a>).
Note that the XGBoost <code>"booster"</code> must be set to
<code>"gbtree"</code>.</p>
</div>
<div class="section level3">
<h3 id="supported-tasks">Supported Tasks<a class="anchor" aria-label="anchor" href="#supported-tasks"></a>
</h3>
<p><code>eagga</code> currently can be used for binary classification
and regression tasks. This might change in the near future to also
include multi-class classification tasks but depends on the concrete
{feature,interaction,monotonicity}.detectors used within
<code>eagga</code> and whether they support multi-class classification.
Moreover, feature types currently must be integer or numeric (also due
to the usage of detectors but anyways required by XGBoost). Although
categorical features can in principle be one-hot or impact encoded,
e.g., via <a href="https://mlr3pipelines.mlr-org.com" class="external-link">mlr3pipelines</a>
by using a suitable <a href="https://mlr3pipelines.mlr-org.com/reference/PipeOp.html" class="external-link"><code>PipeOp</code></a>
and wrapping the pipeop + learner in a <a href="https://mlr3pipelines.mlr-org.com/reference/GraphLearner.html" class="external-link"><code>GraphLearner</code></a>,
the current <code>EAGGA</code> implementation does not support such an
encoding. This behavior might change in the near future. If your use
case includes categorical features or multi-class classification tasks,
please open an issue so that we are aware of it and can work on
implementing proper support with higher priority.</p>
</div>
<div class="section level3">
<h3 id="building-blocks-of-eagga">Building Blocks of EAGGA<a class="anchor" aria-label="anchor" href="#building-blocks-of-eagga"></a>
</h3>
<p>As outlined in the paper, the basic building blocks of
<code>EAGGA</code> are a learner with a hyperparameter search space, a
tabular machine learning task, a resampling method and a performance
metric.</p>
<div class="section level4">
<h4 id="learner-and-search-space">Learner and Search Space<a class="anchor" aria-label="anchor" href="#learner-and-search-space"></a>
</h4>
<p>The learner must support the specification of feature selection as
well as interaction and monotonicity constraints of features. Currently
only <code>XGBoost</code> learners (<a href="https://mlr3learners.mlr-org.com/reference/LearnerClassifXgboost.html" class="external-link"><code>LearnerClassifXgboost</code></a>
or <a href="https://mlr3learners.mlr-org.com/reference/LearnerRegrXgboost.html" class="external-link"><code>mlr3learners::LearnerRegrXgboost</code></a>)
are supported.</p>
<p>Feature selection is handled via <a href="https://mlr3pipelines.mlr-org.com" class="external-link">mlr3pipelines</a> making use of
<a href="https://mlr3pipelines.mlr-org.com/reference/PipeOpSelect.html" class="external-link"><code>mlr3pipelines::PipeOpSelect</code></a>.
<code>EAGGA</code> further makes use of so-called
{feature,interaction,monotonicity}.detectors. For example, the <a href="https://www.rdocumentation.org/packages/eagga/topics/MonotonicityDetector" class="external-link"><code>MonotonicityDetector</code></a>
is used to detect the sign of a feature if it should be constrained to
have a monotone effect on the target. To apply such a sign correction,
the learner must be configured accordingly, this is handled via <a href="https://mlr3pipelines.mlr-org.com/reference/PipeOpColApply.html" class="external-link"><code>mlr3pipelines::PipeOpColApply</code></a>
which will be configured accordingly during optimization. Finally, to
make sure nothing weird happens during optimization, features are always
sorted alphabetically in the internal data representation via <a href="https://www.rdocumentation.org/packages/eagga/topics/PipeOpSortFeatures" class="external-link"><code>eagga::PipeOpSortFeatures</code></a>.</p>
<p>A suitable learner therefore combines all these pipeops and the
learner itself in the form of a <a href="https://mlr3pipelines.mlr-org.com/reference/GraphLearner.html" class="external-link"><code>mlr3pipelines::GraphLearner</code></a>
and will look like the following (assuming classification):</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3.mlr-org.com" class="external-link">mlr3</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://sumny.github.io/eagga/">eagga</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: mlr3tuning</span></span>
<span><span class="co">#&gt; Loading required package: paradox</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3learners.mlr-org.com" class="external-link">mlr3learners</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3pipelines.mlr-org.com" class="external-link">mlr3pipelines</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3misc.mlr-org.com" class="external-link">mlr3misc</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com" class="external-link">data.table</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">2906</span><span class="op">)</span></span>
<span></span>
<span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html" class="external-link">as_learner</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html" class="external-link">po</a></span><span class="op">(</span><span class="st">"colapply"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html" class="external-link">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html" class="external-link">po</a></span><span class="op">(</span><span class="st">"select"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html" class="external-link">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html" class="external-link">po</a></span><span class="op">(</span><span class="st">"sortfeatures"</span><span class="op">)</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html" class="external-link">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">lrn</a></span><span class="op">(</span><span class="st">"classif.xgboost"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">classif.xgboost.booster</span> <span class="op">=</span> <span class="st">"gbtree"</span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">colapply.applicator</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="va">x</span></span></code></pre></div>
<p>Note that we have to set the <code>"classif.xgboost.booster"</code>
hyperparameter to <code>"gbtree"</code>. Moreover, the function to apply
via <a href="https://mlr3pipelines.mlr-org.com/reference/PipeOpColApply.html" class="external-link"><code>PipeOpColApply</code></a>
must be set to <code>function(x) - x</code> (which is responsible for
changing the sign of features after having detected the necessity of
such a swap via using a monotonicity detector as described above).</p>
<p>Users can customize this pipeline building the graph learner but must
adhere to the basic structure
(<code>colapply --&gt; select --&gt; sortfeatures --&gt; [custom user block] --&gt; learner</code>).</p>
<p>The search space defines the hyperparameter search space that should
be optimized over. An example looks like the following:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">search_space</span> <span class="op">=</span> <span class="fu">ps</span><span class="op">(</span></span>
<span>  classif.xgboost.nrounds <span class="op">=</span> <span class="fu">p_dbl</span><span class="op">(</span>lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">500</span><span class="op">)</span>, tags <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"int"</span>, <span class="st">"log"</span><span class="op">)</span>,</span>
<span>    trafo <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, default <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  classif.xgboost.eta <span class="op">=</span> <span class="fu">p_dbl</span><span class="op">(</span>lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1e-4</span><span class="op">)</span>, upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, tags <span class="op">=</span> <span class="st">"log"</span>,</span>
<span>    trafo <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, default <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">0.3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  classif.xgboost.gamma <span class="op">=</span> <span class="fu">p_dbl</span><span class="op">(</span>lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1e-4</span><span class="op">)</span>, upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">7</span><span class="op">)</span>, tags <span class="op">=</span> <span class="st">"log"</span>,</span>
<span>    trafo <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, default <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1e-4</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  classif.xgboost.lambda <span class="op">=</span> <span class="fu">p_dbl</span><span class="op">(</span>lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1e-4</span><span class="op">)</span>, upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span>, tags <span class="op">=</span> <span class="st">"log"</span>,</span>
<span>    trafo <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, default <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  classif.xgboost.alpha <span class="op">=</span> <span class="fu">p_dbl</span><span class="op">(</span>lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1e-4</span><span class="op">)</span>, upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span>, tags <span class="op">=</span> <span class="st">"log"</span>,</span>
<span>    trafo <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, default <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1e-4</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  classif.xgboost.subsample <span class="op">=</span> <span class="fu">p_dbl</span><span class="op">(</span>lower <span class="op">=</span> <span class="fl">0.1</span>, upper <span class="op">=</span> <span class="fl">1</span>, default <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>  classif.xgboost.max_depth <span class="op">=</span> <span class="fu">p_int</span><span class="op">(</span>lower <span class="op">=</span> <span class="fl">1</span>, upper <span class="op">=</span> <span class="fl">20</span>, default <span class="op">=</span> <span class="fl">6</span><span class="op">)</span>,</span>
<span>  classif.xgboost.min_child_weight <span class="op">=</span> <span class="fu">p_dbl</span><span class="op">(</span>lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">150</span><span class="op">)</span>, tags <span class="op">=</span> <span class="st">"log"</span>,</span>
<span>    trafo <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, default <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  classif.xgboost.colsample_bytree <span class="op">=</span> <span class="fu">p_dbl</span><span class="op">(</span>lower <span class="op">=</span> <span class="fl">0.01</span>, upper <span class="op">=</span> <span class="fl">1</span>, default <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>  classif.xgboost.colsample_bylevel <span class="op">=</span> <span class="fu">p_dbl</span><span class="op">(</span>lower <span class="op">=</span> <span class="fl">0.01</span>, upper <span class="op">=</span> <span class="fl">1</span>, default <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>  select.selector <span class="op">=</span> <span class="fu">p_uty</span><span class="op">(</span><span class="op">)</span>,  <span class="co"># must be part of the search space</span></span>
<span>  classif.xgboost.interaction_constraints <span class="op">=</span> <span class="fu">p_uty</span><span class="op">(</span><span class="op">)</span>,  <span class="co"># must be part of the search space</span></span>
<span>  classif.xgboost.monotone_constraints <span class="op">=</span> <span class="fu">p_uty</span><span class="op">(</span><span class="op">)</span>  <span class="co"># must be part of the search space</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>This search space specifies that we tuner over <code>nrounds</code>,
<code>eta</code>, <code>gamma</code>, <code>lambda</code>,
<code>alpha</code>, <code>subsample</code>, <code>max_depth</code>,
<code>min_child_weight</code>, <code>colsample_bytree</code> and
<code>colsample_by_level</code> which are standard hyperparameters of
<code>XGBoost</code> (for an explanation and description, see e.g.,
<code>?xgboost</code> or <a href="https://xgboost.readthedocs.io/en/stable/parameter.html" class="external-link uri">https://xgboost.readthedocs.io/en/stable/parameter.html</a>).
Note that in general it is better to set the upper bound of
<code>nrounds</code> higher (e.g., around <code>log(5000)</code> and the
default to <code>log(500)</code> but we use less boosting rounds to
speed up the following examples.</p>
<p>Additionally, we must specify that we also tune over the feature
<code>selector</code> and <code>interaction_constraints</code> and
<code>monotone_constraints</code> (we specify these as <a href="https://paradox.mlr-org.com/reference/ParamUty.html" class="external-link"><code>ParamUty</code></a>
hyperparameters because they are not directly tunable in a standard way.
However, we need to include them into the search space as
<code>eagga</code> must be able to pass such constraints based on
so-called group structures to the learner.</p>
</div>
<div class="section level4">
<h4 id="task">Task<a class="anchor" aria-label="anchor" href="#task"></a>
</h4>
<p>The task is usually supplied by the user. Here we will use the
following toy task for illustrative purposes:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">generate_task</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">x1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span>  <span class="va">x2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span>, sd <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span>  <span class="va">x3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span>  <span class="va">x4</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">1</span>, max <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="va">x5</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span>  <span class="va">y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">cos</a></span><span class="op">(</span><span class="va">x1</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.1</span> <span class="op">*</span> <span class="va">x2</span> <span class="op">+</span> <span class="fl">1.5</span> <span class="op">*</span> <span class="va">x3</span> <span class="op">+</span> <span class="fl">0.1</span> <span class="op">*</span> <span class="va">x4</span> <span class="op">+</span> <span class="va">x3</span> <span class="op">*</span> <span class="va">x4</span></span>
<span>  <span class="va">y</span> <span class="op">=</span> <span class="va">y</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span>, sd <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span>  <span class="va">label</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"0"</span>, <span class="va">n</span><span class="op">)</span></span>
<span>  <span class="va">label</span><span class="op">[</span><span class="va">y</span> <span class="op">&gt;</span> <span class="fl">0.5</span><span class="op">]</span> <span class="op">=</span> <span class="st">"1"</span></span>
<span>  <span class="va">label</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">label</span><span class="op">)</span></span>
<span>  <span class="va">dat</span> <span class="op">=</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/data.table.html" class="external-link">data.table</a></span><span class="op">(</span>x1 <span class="op">=</span> <span class="va">x1</span>, x2 <span class="op">=</span> <span class="va">x2</span>, x3 <span class="op">=</span> <span class="va">x3</span>, x4 <span class="op">=</span> <span class="va">x4</span>, x5 <span class="op">=</span> <span class="va">x5</span>, label <span class="op">=</span> <span class="va">label</span><span class="op">)</span></span>
<span>  <span class="va">task</span> <span class="op">=</span> <span class="va"><a href="https://mlr3.mlr-org.com/reference/TaskClassif.html" class="external-link">TaskClassif</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="st">"example"</span>, backend <span class="op">=</span> <span class="va">dat</span>, target <span class="op">=</span> <span class="st">"label"</span>, positive <span class="op">=</span> <span class="st">"1"</span><span class="op">)</span></span>
<span>  <span class="va">task</span></span>
<span><span class="op">}</span></span>
<span><span class="va">task</span> <span class="op">=</span> <span class="fu">generate_task</span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span></span></code></pre></div>
<p>In this task, the label is strongly influenced by the features
<code>"x1"</code> and <code>"x3"</code>, whereas <code>"x2"</code> and
<code>"x4"</code> have smaller influence and <code>"x5"</code> is not
used at all. <code>"x1"</code> does have a monotone decreasing effect on
the probability of predicting a label of <code>"1"</code>, whereas
<code>"x2"</code>, <code>"x3"</code> and <code>"x4"</code> all have
varying linear (monotone increasing) effects on the probability of
predicting a label of <code>"1"</code>. Moreover, features
<code>"x3"</code> and <code>"x4"</code> show a simple interaction.</p>
</div>
<div class="section level4">
<h4 id="resampling">Resampling<a class="anchor" aria-label="anchor" href="#resampling"></a>
</h4>
<p>You can use any resampling supported my <a href="https://mlr3.mlr-org.com" class="external-link">mlr3</a>. Here we will use three-fold
cross-validation:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">resampling</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="performance-measure-and-interpretability-measures">Performance Measure (and Interpretability Measures)<a class="anchor" aria-label="anchor" href="#performance-measure-and-interpretability-measures"></a>
</h4>
<p>You can use any performance measure supported by <a href="https://mlr3.mlr-org.com" class="external-link">mlr3</a>. Here we will use the
classification error:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">performance_measure</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span></span></code></pre></div>
<p>As <code>EAGGA</code> jointly optimizes for performance and
interpretability, we also need to pass the interpretability measures
(<code>NF</code>, <code>NI</code> and <code>NNM</code> in the paper):
the relative number of features used by the model, the relative number
of (pariwise) interactions of features in the model and the relative
number of non-monotone feature effects.</p>
<p>These measures are implemented via so-called proxy measures (proxy
because they actually do not work like standard mlr3 measures and do not
operate on a <a href="https://mlr3.mlr-org.com/reference/Prediction.html" class="external-link"><code>Prediction</code></a>
object but rather are always hard coded to a value of zero but updated
and computed within the actual optimization process).</p>
<p>For details, see <a href="https://www.rdocumentation.org/packages/eagga/topics/MeasureSelectedFeaturesProxy" class="external-link"><code>MeasureSelectedFeaturesProxy</code></a>,
<a href="https://www.rdocumentation.org/packages/eagga/topics/MeasureSelectedInteractionsProxy" class="external-link"><code>MeasureSelectedInteractionsProxy</code></a>
and <a href="https://www.rdocumentation.org/packages/eagga/topics/MeasureSelectedNonMonotoneProxy" class="external-link"><code>MeasureSelectedNonMonotoneProxy</code></a>.</p>
<p>Again, note that these measures do not do anything meaningful except
for when being used in combination with <code>eagga</code>.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">measures</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">performance_measure</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">msr</a></span><span class="op">(</span><span class="st">"selected_features_proxy"</span><span class="op">)</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">msr</a></span><span class="op">(</span><span class="st">"selected_interactions_proxy"</span><span class="op">)</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">msr</a></span><span class="op">(</span><span class="st">"selected_non_monotone_proxy"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
</div>
<div class="section level2">
<h2 id="tuning-with-tunereagga">Tuning with TunerEAGGA<a class="anchor" aria-label="anchor" href="#tuning-with-tunereagga"></a>
</h2>
<p>As we have introduced all building blocks, we can now use
<code>EAGGA</code> to jointly optimize for performance and
interpretability. This works by constructing a <a href="https://mlr3tuning.mlr-org.com/reference/TuningInstanceMultiCrit.html" class="external-link"><code>TuningInstanceMultiCrit</code></a>
and a <a href="https://www.rdocumentation.org/packages/eagga/topics/TunerEAGGA" class="external-link"><code>TunerEAGGA</code></a>.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span> <span class="op">=</span> <span class="va"><a href="https://mlr3tuning.mlr-org.com/reference/TuningInstanceMultiCrit.html" class="external-link">TuningInstanceMultiCrit</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span></span>
<span>  task <span class="op">=</span> <span class="va">task</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">learner</span>,</span>
<span>  resampling <span class="op">=</span> <span class="va">resampling</span>, </span>
<span>  measures <span class="op">=</span> <span class="va">measures</span>,</span>
<span>  terminator <span class="op">=</span> <span class="fu"><a href="https://bbotk.mlr-org.com/reference/trm.html" class="external-link">trm</a></span><span class="op">(</span><span class="st">"evals"</span>, n_evals <span class="op">=</span> <span class="fl">30</span><span class="op">)</span>,</span>
<span>  search_space <span class="op">=</span> <span class="va">search_space</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>By setting <code>terminator = trm("evals", n_evals = 30)</code> we
specify that termination of the tuning process should occur after having
evaluated 30 configurations. This is sufficient for illustrative
purposes here but should be set much higher in practice. Termination can
also be specified via other terminators, see, e.g.,
<code><a href="https://bbotk.mlr-org.com/reference/mlr_terminators.html" class="external-link">?mlr_terminators</a></code></p>
<p>We now construct the tuner. For everything to smoothly work together,
we have to explicitly tell the tuner the pipeop <code>id</code> of the
learner within the graph learner via <code>learner_id</code>. Moreover,
we have to specify the parameter <code>id</code> of the interaction
constraint and monotonicity constraint hyperparameters via
<code>interaction_id</code> and <code>monotone_id</code>. We can further
specify the population size via <code>mu</code> and the offspring size
via <code>lambda</code>. Here we set them to <code>mu = 10</code> and
<code>lambda = 2</code> for illustrative purposes (usually they should
be set much higher; a good starting point can be <code>mu = 100</code>
and <code>lambda = 10</code>). Furthermore we can specify
<code>seed_calculate_proxy_measures</code> to seed the model fitting
process of configurations tried during optimization on the task to be
able to fully reproduce models resulting in certain <code>NF</code>,
<code>NI</code>, and <code>NNM</code> values found during optimization.
For more details, see the section on reconstructing models below.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tuner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3tuning.mlr-org.com/reference/tnr.html" class="external-link">tnr</a></span><span class="op">(</span><span class="st">"eagga"</span>,</span>
<span>  learner_id <span class="op">=</span> <span class="st">"classif.xgboost"</span>,</span>
<span>  select_id <span class="op">=</span> <span class="st">"select.selector"</span>,</span>
<span>  interaction_id <span class="op">=</span> <span class="st">"classif.xgboost.interaction_constraints"</span>,</span>
<span>  monotone_id <span class="op">=</span> <span class="st">"classif.xgboost.monotone_constraints"</span>,</span>
<span>  mu <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  seed_calculate_proxy_measures <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We can now start the optimization process:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tuner</span><span class="op">$</span><span class="fu">optimize</span><span class="op">(</span><span class="va">instance</span><span class="op">)</span></span>
<span><span class="co">#&gt;     classif.xgboost.nrounds classif.xgboost.eta classif.xgboost.gamma</span></span>
<span><span class="co">#&gt;  1:                4.579827          -0.1562697             -7.809646</span></span>
<span><span class="co">#&gt;  2:                3.221994          -1.4195552             -7.715113</span></span>
<span><span class="co">#&gt;  3:                3.559853          -0.1725791             -9.210340</span></span>
<span><span class="co">#&gt;  4:                3.559853          -0.1725791             -9.210340</span></span>
<span><span class="co">#&gt;  5:                3.912023          -1.2039728             -9.210340</span></span>
<span><span class="co">#&gt;  6:                4.579827          -0.1562697             -7.809646</span></span>
<span><span class="co">#&gt;  7:                4.579827          -0.1562697             -7.809646</span></span>
<span><span class="co">#&gt;  8:                3.303761          -1.3299372             -8.878691</span></span>
<span><span class="co">#&gt;  9:                3.559853          -0.1562697             -7.809646</span></span>
<span><span class="co">#&gt; 10:                4.579827          -0.1725791             -9.210340</span></span>
<span><span class="co">#&gt; 11:                3.559853          -0.1725791             -9.210340</span></span>
<span><span class="co">#&gt; 12:                3.559853          -0.1725791             -9.210340</span></span>
<span><span class="co">#&gt; 13:                3.303761          -1.3299372             -8.878691</span></span>
<span><span class="co">#&gt; 14:                3.221994          -1.4195552             -7.715113</span></span>
<span><span class="co">#&gt; 15:                3.221994          -1.4195552             -7.715113</span></span>
<span><span class="co">#&gt; 16:                3.912023          -1.2039728             -9.210340</span></span>
<span><span class="co">#&gt; 17:                3.912023          -1.2039728             -9.210340</span></span>
<span><span class="co">#&gt;     classif.xgboost.lambda classif.xgboost.alpha classif.xgboost.subsample</span></span>
<span><span class="co">#&gt;  1:              -3.167346             -9.210340                 1.0000000</span></span>
<span><span class="co">#&gt;  2:               3.822008             -9.210340                 0.9988563</span></span>
<span><span class="co">#&gt;  3:               2.075947             -8.710336                 0.9207827</span></span>
<span><span class="co">#&gt;  4:               2.075947             -8.710336                 0.9207827</span></span>
<span><span class="co">#&gt;  5:               0.000000             -9.210340                 1.0000000</span></span>
<span><span class="co">#&gt;  6:              -3.167346             -9.210340                 0.9988563</span></span>
<span><span class="co">#&gt;  7:              -3.167346             -9.210340                 1.0000000</span></span>
<span><span class="co">#&gt;  8:              -1.355523             -7.639524                 1.0000000</span></span>
<span><span class="co">#&gt;  9:               2.151026             -9.210340                 0.9207827</span></span>
<span><span class="co">#&gt; 10:              -3.167346             -8.710336                 0.9988563</span></span>
<span><span class="co">#&gt; 11:               2.075947             -8.710336                 0.9207827</span></span>
<span><span class="co">#&gt; 12:               2.075947             -8.710336                 0.9207827</span></span>
<span><span class="co">#&gt; 13:              -1.355523             -7.639524                 1.0000000</span></span>
<span><span class="co">#&gt; 14:               3.822008             -9.210340                 0.9988563</span></span>
<span><span class="co">#&gt; 15:               5.428247             -9.210340                 1.0000000</span></span>
<span><span class="co">#&gt; 16:               0.000000             -9.210340                 1.0000000</span></span>
<span><span class="co">#&gt; 17:               0.000000             -9.210340                 1.0000000</span></span>
<span><span class="co">#&gt;     classif.xgboost.max_depth classif.xgboost.min_child_weight</span></span>
<span><span class="co">#&gt;  1:                         4                        1.5855743</span></span>
<span><span class="co">#&gt;  2:                         8                        0.4933049</span></span>
<span><span class="co">#&gt;  3:                         5                        0.9270958</span></span>
<span><span class="co">#&gt;  4:                         5                        0.9270958</span></span>
<span><span class="co">#&gt;  5:                         6                        1.0000000</span></span>
<span><span class="co">#&gt;  6:                         8                        1.5855743</span></span>
<span><span class="co">#&gt;  7:                         4                        1.5855743</span></span>
<span><span class="co">#&gt;  8:                         6                        0.8530992</span></span>
<span><span class="co">#&gt;  9:                         9                        0.9270958</span></span>
<span><span class="co">#&gt; 10:                         5                        1.5855743</span></span>
<span><span class="co">#&gt; 11:                         5                        0.9270958</span></span>
<span><span class="co">#&gt; 12:                         5                        0.9270958</span></span>
<span><span class="co">#&gt; 13:                         6                        0.8530992</span></span>
<span><span class="co">#&gt; 14:                         8                        0.4933049</span></span>
<span><span class="co">#&gt; 15:                         4                        0.4933049</span></span>
<span><span class="co">#&gt; 16:                         6                        1.0000000</span></span>
<span><span class="co">#&gt; 17:                         6                        1.0000000</span></span>
<span><span class="co">#&gt;     classif.xgboost.colsample_bytree classif.xgboost.colsample_bylevel</span></span>
<span><span class="co">#&gt;  1:                        1.0000000                         1.0000000</span></span>
<span><span class="co">#&gt;  2:                        0.9711652                         0.9816349</span></span>
<span><span class="co">#&gt;  3:                        0.8474910                         0.8997374</span></span>
<span><span class="co">#&gt;  4:                        0.8474910                         0.8997374</span></span>
<span><span class="co">#&gt;  5:                        1.0000000                         1.0000000</span></span>
<span><span class="co">#&gt;  6:                        1.0000000                         0.9816349</span></span>
<span><span class="co">#&gt;  7:                        1.0000000                         0.9816349</span></span>
<span><span class="co">#&gt;  8:                        1.0000000                         0.9875292</span></span>
<span><span class="co">#&gt;  9:                        1.0000000                         0.8997374</span></span>
<span><span class="co">#&gt; 10:                        0.8474910                         0.9816349</span></span>
<span><span class="co">#&gt; 11:                        0.8474910                         0.8997374</span></span>
<span><span class="co">#&gt; 12:                        0.8474910                         0.8997374</span></span>
<span><span class="co">#&gt; 13:                        1.0000000                         0.9875292</span></span>
<span><span class="co">#&gt; 14:                        0.9711652                         0.9816349</span></span>
<span><span class="co">#&gt; 15:                        0.9711652                         1.0000000</span></span>
<span><span class="co">#&gt; 16:                        1.0000000                         1.0000000</span></span>
<span><span class="co">#&gt; 17:                        1.0000000                         1.0000000</span></span>
<span><span class="co">#&gt;     select.selector classif.xgboost.interaction_constraints</span></span>
<span><span class="co">#&gt;  1:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt;  2:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt;  3:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt;  4:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt;  5:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt;  6:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt;  7:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt;  8:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt;  9:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt; 10:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt; 11:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt; 12:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt; 13:   &lt;Selector[1]&gt;                               &lt;list[2]&gt;</span></span>
<span><span class="co">#&gt; 14:   &lt;Selector[1]&gt;                               &lt;list[2]&gt;</span></span>
<span><span class="co">#&gt; 15:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt; 16:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt; 17:   &lt;Selector[1]&gt;                               &lt;list[1]&gt;</span></span>
<span><span class="co">#&gt;     classif.xgboost.monotone_constraints learner_param_vals   x_domain</span></span>
<span><span class="co">#&gt;  1:                                  1,1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt;  2:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt;  3:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt;  4:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt;  5:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt;  6:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt;  7:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt;  8:                                1,1,1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt;  9:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt; 10:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt; 11:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt; 12:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt; 13:                                1,1,0         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt; 14:                                  1,1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt; 15:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt; 16:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt; 17:                                    1         &lt;list[19]&gt; &lt;list[13]&gt;</span></span>
<span><span class="co">#&gt;     classif.ce selected_features_proxy selected_interactions_proxy</span></span>
<span><span class="co">#&gt;  1: 0.06500213                     0.4                         0.1</span></span>
<span><span class="co">#&gt;  2: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt;  3: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt;  4: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt;  5: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt;  6: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt;  7: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt;  8: 0.02801005                     0.6                         0.3</span></span>
<span><span class="co">#&gt;  9: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt; 10: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt; 11: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt; 12: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt; 13: 0.06400712                     0.6                         0.1</span></span>
<span><span class="co">#&gt; 14: 0.07600115                     0.4                         0.0</span></span>
<span><span class="co">#&gt; 15: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt; 16: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt; 17: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt;     selected_non_monotone_proxy</span></span>
<span><span class="co">#&gt;  1:                         0.0</span></span>
<span><span class="co">#&gt;  2:                         0.0</span></span>
<span><span class="co">#&gt;  3:                         0.0</span></span>
<span><span class="co">#&gt;  4:                         0.0</span></span>
<span><span class="co">#&gt;  5:                         0.0</span></span>
<span><span class="co">#&gt;  6:                         0.0</span></span>
<span><span class="co">#&gt;  7:                         0.0</span></span>
<span><span class="co">#&gt;  8:                         0.0</span></span>
<span><span class="co">#&gt;  9:                         0.0</span></span>
<span><span class="co">#&gt; 10:                         0.0</span></span>
<span><span class="co">#&gt; 11:                         0.0</span></span>
<span><span class="co">#&gt; 12:                         0.0</span></span>
<span><span class="co">#&gt; 13:                         0.2</span></span>
<span><span class="co">#&gt; 14:                         0.0</span></span>
<span><span class="co">#&gt; 15:                         0.0</span></span>
<span><span class="co">#&gt; 16:                         0.0</span></span>
<span><span class="co">#&gt; 17:                         0.0</span></span></code></pre></div>
<p>We can then inspect the Pareto front:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">measure_ids</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"classif.ce"</span>,</span>
<span>  <span class="st">"selected_features_proxy"</span>,</span>
<span>  <span class="st">"selected_interactions_proxy"</span>,</span>
<span>  <span class="st">"selected_non_monotone_proxy"</span><span class="op">)</span></span>
<span><span class="va">front</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/unique.html" class="external-link">unique</a></span><span class="op">(</span><span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">$</span><span class="fu">best</span><span class="op">(</span><span class="op">)</span><span class="op">[</span>, <span class="va">measure_ids</span>, with <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/setorder.html" class="external-link">setorderv</a></span><span class="op">(</span><span class="va">front</span>, cols <span class="op">=</span> <span class="st">"classif.ce"</span><span class="op">)</span></span>
<span><span class="va">front</span></span>
<span><span class="co">#&gt;    classif.ce selected_features_proxy selected_interactions_proxy</span></span>
<span><span class="co">#&gt; 1: 0.02801005                     0.6                         0.3</span></span>
<span><span class="co">#&gt; 2: 0.06400712                     0.6                         0.1</span></span>
<span><span class="co">#&gt; 3: 0.06500213                     0.4                         0.1</span></span>
<span><span class="co">#&gt; 4: 0.07600115                     0.4                         0.0</span></span>
<span><span class="co">#&gt; 5: 0.16600732                     0.2                         0.0</span></span>
<span><span class="co">#&gt;    selected_non_monotone_proxy</span></span>
<span><span class="co">#&gt; 1:                         0.0</span></span>
<span><span class="co">#&gt; 2:                         0.2</span></span>
<span><span class="co">#&gt; 3:                         0.0</span></span>
<span><span class="co">#&gt; 4:                         0.0</span></span>
<span><span class="co">#&gt; 5:                         0.0</span></span></code></pre></div>
<p>We observe that we found diverse models trading off performance and
interpretability to varying degree. We can further inspect the group
structure of each model (for more details on the <a href="https://www.rdocumentation.org/packages/eagga/topics/GroupStructure" class="external-link"><code>GroupStructure</code></a>
class, see the technical details section below):</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">$</span><span class="fu">best</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="fl">8</span>, <span class="op">]</span><span class="op">$</span><span class="va">groupstructure</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="fu">get_groups</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [1] "x2" "x5"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[2]]</span></span>
<span><span class="co">#&gt; [1] "x1" "x3" "x4"</span></span></code></pre></div>
<p>We see that in this model, features <code>"x2"</code> and
<code>"x5"</code> are not used (as they are in the first, â€œunselectedâ€
group of features), whereas <code>"x1"</code>, <code>"x3"</code> and
<code>"x4"</code> are allowed to interact (as they are in the second
group, grouped together).</p>
<p>Moreover,</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">$</span><span class="fu">best</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="fl">8</span>, <span class="op">]</span><span class="op">$</span><span class="va">groupstructure</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">monotone_features</span></span>
<span><span class="co">#&gt;    feature monotonicity</span></span>
<span><span class="co">#&gt; 1:      x1            1</span></span>
<span><span class="co">#&gt; 2:      x2           NA</span></span>
<span><span class="co">#&gt; 3:      x3            1</span></span>
<span><span class="co">#&gt; 4:      x4            1</span></span>
<span><span class="co">#&gt; 5:      x5           NA</span></span></code></pre></div>
<p>tells us that <code>"x1"</code>, <code>"x3"</code> and
<code>"x4"</code> are constrained to have a monotone (increasing) effect
on the feature. But wait, didnâ€™t we say that in our toy task,
<code>"x1"</code> has a monotone decreasing effect on the target? Yes,
but: As our <a href="https://www.rdocumentation.org/packages/eagga/topics/MonotonicityDetector" class="external-link"><code>MonotonicityDetector</code></a>
within <code>EAGGA</code> detected <code>"x1"</code> to have a monotone
decreasing effect (if enforced) and we were able to swap the sign of the
feature itself to then enforce a monotone increasing effect (and in
<code>EAGGA</code> we only want to differentiate between unconstrained
or monotone increasing feature effects):</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">mlr3misc</span><span class="fu">::</span><span class="fu"><a href="https://mlr3misc.mlr-org.com/reference/get_private.html" class="external-link">get_private</a></span><span class="op">(</span><span class="va">tuner</span><span class="op">)</span><span class="op">$</span><span class="va">.monotonicity_detector</span><span class="op">$</span><span class="fu">get_sign</span><span class="op">(</span><span class="st">"x1"</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] -1</span></span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">instance</span><span class="op">$</span><span class="va">objective</span><span class="op">$</span><span class="va">learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">colapply.affect_columns</span></span>
<span><span class="co">#&gt; selector_name("x1")</span></span></code></pre></div>
<p>Note: As this process of swapping the sign of features is performed
during optimization, you cannot simply use the learner you passed to the
instance afterwards to train your learner with a given hyperparameter
configuration and group structure. Instead, you should use the learner
within the objective of the instance which was updated in place:
<code>instance$objective$learner</code>. To use a hyperparameter
configuration and group structure together with this learner, you can
then do the following. Assume we want to use the eighth configuration of
the Pareto set, then we can simply specify the hyperparameter values as
follows:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hpc</span> <span class="op">=</span> <span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">$</span><span class="fu">best</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="fl">8</span>, <span class="st">"x_domain"</span><span class="op">]</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">learner</span> <span class="op">=</span> <span class="va">instance</span><span class="op">$</span><span class="va">objective</span><span class="op">$</span><span class="va">learner</span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3misc.mlr-org.com/reference/insert_named.html" class="external-link">insert_named</a></span><span class="op">(</span><span class="va">learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span>, <span class="va">hpc</span><span class="op">)</span></span></code></pre></div>
<p>However, as <code>EAGGA</code> uses a feedback loop during
optimization to update the feature selection, feature interaction and
monotonicity constraints based on the actual structures found in the
model (tightening the upper bound of the group structure passed to the
learner to fit the model and updating this original group structure post
hoc), some more additional steps are needed to fully reconstruct a model
found during optimization.</p>
<p>In essence, this involves re-creating the feature selection, feature
interaction and monotonicity constraints from the original group
structure that was used to fit the model (prior to that group structure
being updated by the feedback loop):</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">groupstructure_orig</span> <span class="op">=</span> <span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">$</span><span class="fu">best</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="fl">8</span>, <span class="st">"groupstructure_orig"</span><span class="op">]</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">hpc</span><span class="op">$</span><span class="va">select.selector</span> <span class="op">=</span> <span class="va">groupstructure_orig</span><span class="op">$</span><span class="fu">create_selector</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">hpc</span><span class="op">$</span><span class="va">classif.xgboost.interaction_constraints</span> <span class="op">=</span> <span class="va">groupstructure_orig</span><span class="op">$</span><span class="fu">create_interaction_constraints</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">hpc</span><span class="op">$</span><span class="va">classif.xgboost.monotone_constraints</span> <span class="op">=</span> <span class="va">groupstructure_orig</span><span class="op">$</span><span class="fu">create_monotonicity_constraints</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3misc.mlr-org.com/reference/insert_named.html" class="external-link">insert_named</a></span><span class="op">(</span><span class="va">learner</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span>, <span class="va">hpc</span><span class="op">)</span></span></code></pre></div>
<p>To make this easier, the following section describes a more automated
way.</p>
</div>
<div class="section level2">
<h2 id="deciding-on-a-model-and-reconstructing-it">Deciding on a Model and Reconstructing it<a class="anchor" aria-label="anchor" href="#deciding-on-a-model-and-reconstructing-it"></a>
</h2>
<p>Once we have decided on a model (based on a non-dominated
hyperparameter configuration and group structure) we prefer, we can
â€œreconstructâ€ it. To do so, we use the <a href="https://www.rdocumentation.org/packages/eagga/topics/reconstruct_eagga_model" class="external-link"><code>reconstruct_eagga_model</code></a>
function and pass the tuning instance, the tuner and the uhash of the
model we want to â€œreconstructâ€ as logged in the archive:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">uhash</span> <span class="op">=</span> <span class="va">instance</span><span class="op">$</span><span class="va">archive</span><span class="op">$</span><span class="fu">best</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">uhash</span><span class="op">[</span><span class="fl">8</span><span class="op">]</span></span>
<span><span class="va">model</span> <span class="op">=</span> <span class="fu"><a href="../reference/reconstruct_eagga_model.html">reconstruct_eagga_model</a></span><span class="op">(</span><span class="va">instance</span>, tuner <span class="op">=</span> <span class="va">tuner</span>, model_uhash <span class="op">=</span> <span class="va">uhash</span><span class="op">)</span></span></code></pre></div>
<p>We can then use this model as any other trained learner, for example,
if we want to predict on new data:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">task_test</span> <span class="op">=</span> <span class="fu">generate_task</span><span class="op">(</span><span class="fl">10000</span><span class="op">)</span></span>
<span><span class="va">model</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">task_test</span><span class="op">)</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html" class="external-link">msr</a></span><span class="op">(</span><span class="st">"classif.ce"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; classif.ce </span></span>
<span><span class="co">#&gt;     0.0341</span></span></code></pre></div>
<p>In general, note that the performance estimates obtained during
optimization via a resampling method can be biased estimates of the
performance of the final model, as we have based our decision making
process on these performance estimate (this is in essence the same
problem as in single objective hyperparameter optimization and why we
should use nested resampling to get an unbiased estimate of the
performance of the final model). Ideally, you do have access to some
unseen test data as illustrated above.</p>
</div>
<div class="section level2">
<h2 id="inspecting-models-with-the-iml-package">Inspecting Models with the iml Package<a class="anchor" aria-label="anchor" href="#inspecting-models-with-the-iml-package"></a>
</h2>
<p>As <a href="https://mlr3.mlr-org.com" class="external-link">mlr3</a> nicely interplays with
the <a href="https://cran.r-project.org/package=iml" class="external-link">iml</a> package, we
can easily use post-hoc interpretable ML techniques to gain some more
insights into a model of our choice. For example, we can look at ALE
plots of each feature:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span><span class="op">$</span><span class="va">predict_type</span> <span class="op">=</span> <span class="st">"prob"</span></span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://christophm.github.io/iml/" class="external-link">iml</a></span><span class="op">)</span></span>
<span><span class="va">predictor</span> <span class="op">=</span> <span class="va"><a href="https://christophm.github.io/iml/reference/Predictor.html" class="external-link">Predictor</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">task</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span>cols <span class="op">=</span> <span class="va">task</span><span class="op">$</span><span class="va">feature_names</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="va">task</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span>cols <span class="op">=</span> <span class="va">task</span><span class="op">$</span><span class="va">target_names</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">effect_x2</span> <span class="op">=</span> <span class="va"><a href="https://christophm.github.io/iml/reference/FeatureEffect.html" class="external-link">FeatureEffect</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">predictor</span>, feature <span class="op">=</span> <span class="st">"x2"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">effect_x2</span><span class="op">)</span></span></code></pre></div>
<p><img src="eagga_files/figure-html/unnamed-chunk-22-1.png" width="700"></p>
<p>As expected the ALE plot shows us that feature <code>"x2</code> has
no effect on the target as it cannot be used by the model:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">select.selector</span></span>
<span><span class="co">#&gt; selector_name(c("x1", "x3", "x4"))</span></span></code></pre></div>
<p>Similarly, we can look at other featues:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">effect_x3</span> <span class="op">=</span> <span class="va"><a href="https://christophm.github.io/iml/reference/FeatureEffect.html" class="external-link">FeatureEffect</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">predictor</span>, feature <span class="op">=</span> <span class="st">"x3"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">effect_x3</span><span class="op">)</span></span></code></pre></div>
<p><img src="eagga_files/figure-html/unnamed-chunk-24-1.png" width="700"></p>
<p>We know that feature <code>"x3"</code> can be used by the model and
is constrained to have a monotone increasing effect on the target -
which is also confirmed by the ALE plot. However, recall that our
monotonicity detector during optimization detected that
<code>"x3"</code> actually should have a monotone decreasing effect on
the target and to achieve a monotone increasing effect we switched the
sign of the feature. This is â€œhiddenâ€ in the ALE plot, i..e, it looks as
if <code>"x3"</code> indeed has a monotone increasing feature effect on
predicting the positive class label <code>"1"</code> - but the actual
monotonicity direction is a decreasing one as we have swapped the sign
of the feature (so be careful when interpreting the monotonicity of
feature effects, if signs have been swapped during optimization).</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">colapply.affect_columns</span></span>
<span><span class="co">#&gt; selector_name("x1")</span></span>
<span><span class="va">model</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">colapply.applicator</span></span>
<span><span class="co">#&gt; function(x) - x</span></span>
<span><span class="co">#&gt; &lt;bytecode: 0x5615d30faea0&gt;</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="technical-details">Technical Details<a class="anchor" aria-label="anchor" href="#technical-details"></a>
</h2>
<p>This section is work in progress and will explain technical details
of the <a href="https://www.rdocumentation.org/packages/eagga/topics/TunerEAGGA" class="external-link"><code>TunerEAGGA</code></a>,
<a href="https://www.rdocumentation.org/packages/eagga/topics/Probs" class="external-link"><code>Probs</code></a>,
<a href="https://www.rdocumentation.org/packages/eagga/topics/InteractionDetector" class="external-link"><code>InteractionDetector</code></a>,
<a href="https://www.rdocumentation.org/packages/eagga/topics/MonotonicityDetector" class="external-link"><code>MonotonicityDetector</code></a>
and <a href="https://www.rdocumentation.org/packages/eagga/topics/GroupStructure" class="external-link"><code>GroupStructure</code></a>
classes. Note that the feature detector is currently implemented within
<a href="https://www.rdocumentation.org/packages/eagga/topics/TunerEAGGA" class="external-link"><code>TunerEAGGA</code></a>
directly and not exposed as a standalone class but this might change in
the near future. The current feature detector is simply based on a <a href="https://mlr3filters.mlr-org.com/reference/FilterInformationGain.html" class="external-link"><code>FilterInformationGain</code></a>.</p>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-schneider_2023" class="csl-entry">
Schneider, Lennart, Bernd Bischl, and Janek Thomas. 2023.
<span>â€œMulti-Objective Optimization of Performance and Interpretability
of Tabular Supervised Machine Learning Models.â€</span> In
<em>Proceedings of the Genetic and Evolutionary Computation
Conference</em>, 538â€“47. GECCO â€™23. <a href="https://doi.org/10.1145/3583131.3590380" class="external-link">https://doi.org/10.1145/3583131.3590380</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Lennart Schneider.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
