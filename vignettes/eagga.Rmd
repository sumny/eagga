---
title: "eagga"
subtitle: "Get started"
output: rmarkdown::html_vignette
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{eagga}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

update_db = function() {
  if (is.null(db$base) || is.null(db$aliases)) {
    hdb = hsearch_db(package = unique(c(db$index, db$hosted)), types = "help")
    db$base = setkeyv(as.data.table(hdb$Base), "ID")
    db$aliases = setkeyv(as.data.table(hdb$Aliases), "Alias")
  }
}

#' @title Hyperlink to Function Reference
#'
#' @description
#' Creates a markdown link to a function reference.
#'
#' @param topic Name of the topic to link against.
#' @param text Text to use for the link. Defaults to the topic name.
#' @param format Either markdown or HTML.
#'
#' @return (`character(1)`) markdown link.
ref = function(topic, text = topic, format = "markdown") {
  strip_parenthesis = function(x) sub("\\(\\)$", "", x)

  checkmate::assert_string(topic, pattern = "^[[:alnum:]._-]+(::[[:alnum:]._-]+)?(\\(\\))?$")
  checkmate::assert_string(text, min.chars = 1L)
  checkmate::assert_choice(format, c("markdown", "html"))

  topic = trimws(topic)
  text = trimws(text)

  if (stringi::stri_detect_fixed(topic, "::")) {
    parts = strsplit(topic, "::", fixed = TRUE)[[1L]]
    topic = parts[2L]
    name = strip_parenthesis(parts[2L])
    pkg = parts[1L]
  } else {
    update_db()
    matched = db$base[db$aliases[list(strip_parenthesis(topic)), c("Alias", "ID"), on = "Alias", nomatch = 0L], on = "ID", nomatch = NULL]
    if (nrow(matched) == 0L) {
      stop(sprintf("Could not find help page for topic '%s'", topic))
    }
    if (nrow(matched) >= 2L) {
      lgr$warn("Ambiguous link to '%s': %s", topic, paste0(paste(matched$Package, matched$Name, sep = "::"), collapse = " | "))
      matched = head(matched, 1L)
    }

    pkg = matched$Package
    name = matched$Name
    lgr$debug("Resolved '%s' to '%s::%s'", topic, pkg, name)
  }

  if (pkg %in% db$hosted) {
    url = sprintf("https://%s.mlr-org.com/reference/%s.html", pkg, name)
  } else {
    url = sprintf("https://www.rdocumentation.org/packages/%s/topics/%s", pkg, name)
  }

  switch(format,
    "markdown" = sprintf("[`%s`](%s)", text, url),
    "html" = sprintf("<a href=\"%s\">%s</a>", url, text)
  )
}

#' @title Hyperlink to Package
#'
#' @description
#' Links either to respective mlr3 website or to CRAN page.
#'
#' @param pkg Name of the package.
#' @inheritParams ref
#'
#' @return (`character(1)`) markdown link.
#' @export
ref_pkg = function(pkg, format = "markdown") {
  checkmate::assert_string(pkg, pattern = "^[[:alnum:]._-]+$")
  checkmate::assert_choice(format, c("markdown", "html"))
  pkg = trimws(pkg)

  if (grepl("/", pkg, fixed = TRUE)) {
    gh_pkg(pkg, format = format)
  } else if (pkg %in% db$hosted) {
    mlr_pkg(pkg, format = format)
  } else {
    cran_pkg(pkg, format = format)
  }
}

#' @title Hyperlink to CRAN Package
#'
#' @description
#' Creates a markdown link to a CRAN package.
#'
#' @inheritParams ref_pkg
#'
#' @return (`character(1)`) markdown link.
cran_pkg = function(pkg, format = "markdown") {
  checkmate::assert_string(pkg, pattern = "^[[:alnum:]._-]+$")
  checkmate::assert_choice(format, c("markdown", "html"))
  pkg = trimws(pkg)

  if (pkg %in% c("stats", "graphics", "datasets")) {
    return(pkg)
  }
  url = sprintf("https://cran.r-project.org/package=%s", pkg)
  switch(format,
    "markdown" = sprintf("[%s](%s)", pkg, url),
    "html" = sprintf("<a href = \"%s\">%s</a>", url, pkg)
  )
}

#' @title Hyperlink to mlr3 Package
#'
#' @description
#' Creates a markdown link to a mlr3 package with a "mlr-org.com" subdomain.
#'
#' @inheritParams ref_pkg
#'
#' @return (`character(1)`) markdown link.
mlr_pkg = function(pkg, format = "markdown") {
  checkmate::assert_string(pkg, pattern = "^[[:alnum:]._-]+$")
  checkmate::assert_choice(format, c("markdown", "html"))
  pkg = trimws(pkg)

  url = sprintf("https://%1$s.mlr-org.com", pkg)
  switch(format,
    "markdown" = sprintf("[%s](%s)", pkg, url),
    "html" = sprintf("<a href = \"%s\">%s</a>", url, pkg)
  )
}

#' @title Hyperlink to GitHub Repository
#'
#' @description
#' Creates a markdown link to GitHub repository.
#'
#' @param pkg Name of the repository specified as "{repo}/{name}".
#' @inheritParams ref_pkg
#'
#' @return (`character(1)`) markdown link.
gh_pkg = function(pkg, format = "markdown") {
  checkmate::assert_string(pkg, pattern = "^[[:alnum:]_-]+/[[:alnum:]._-]+$")
  checkmate::assert_choice(format, c("markdown", "html"))
  pkg = trimws(pkg)

  parts = strsplit(pkg, "/", fixed = TRUE)[[1L]]
  url = sprintf("https://github.com/%s", pkg)
  switch(format,
    "markdown" = sprintf("[%s](%s)", parts[2L], url),
    "html" = sprintf("<a href = \"%s\">%s</a>", url, parts[2L])
  )
}

db = new.env()
db$index = c("base", "utils", "datasets", "data.table", "stats")
db$hosted = c("paradox", "mlr3misc", "mlr3", "mlr3data", "mlr3db", "mlr3proba", "mlr3pipelines", "mlr3learners", "mlr3filters", "bbotk", "mlr3tuning", "mlr3viz", "mlr3fselect", "mlr3cluster", "mlr3spatiotempcv", "mlr3spatial", "mlr3extralearners", "mlr3tuningspaces", "mlr3hyperband", "mlr3mbo")

lgr = NULL
```

# Intro

The `EAGGA` algorithm is a model-agnostic framework designed to jointly optimize the predictive performance and interpretability of supervised machine learning models for tabular data.
This algorithm incorporates three key measures of interpretability: feature sparsity, interaction sparsity of features, and sparsity of non-monotone feature effects.

By formulating the hyperparameter optimization process of a machine learning algorithm as a multi-objective optimization problem, `EAGGA` enables the generation of diverse models that strike a balance between high performance and interpretability within a single optimization run.
Efficient optimization is achieved by expanding the search space of the learning algorithm through the inclusion of feature selection, interaction, and monotonicity constraints in the hyperparameter search which are represented in the form of a groupstructure.

The core concept behind `EAGGA` lies in identifying the Pareto optimal set of groups of selected features that can interact within a model, along with determining their optimal monotonicity constraints and the optimal hyperparameters of the learning algorithm itself.

This vignette is a gentle introduction to the core functionality of the `eagga` package.
For more details on the algorithm itself, please see @schneider_2023.
Note that the `eagga` package heavily builds upon the `mlr3` ecosystem.
If you are not familiar with it, we highly recommend to make yourself familiar with it, by for example reading the following book: https://mlr3book.mlr-org.com/

As a final comment: In the following, we will write `EAGGA` to refer to the algorithm, whereas `eagga` will refer to the software implementation, i.e., the R package this vignette is introducing.


# Technical Preliminaries

## Supported Learners

Although formulated model-agnostic, the current `EAGGA` implementation currently only supports `XGBoost` learners (`r ref("mlr3learners::LearnerClassifXgboost", "LearnerClassifXgboost")` or `r ref("mlr3learners::LearnerRegrXgboost")`).
Note that the XGBoost `"booster"` must be set to `"gbtree"`.

## Supported Tasks

`eagga` currently can be used for binary classification and regression tasks.
This might change in the near future to also include multi-class classification tasks but depends on the concrete {feature,interaction,monotonicity}.detectors used within `eagga` and whether they support multi-class classification.
Moreover, feature types currently must be integer or numeric (also due to the usage of detectors but anyways required by XGBoost).
Although categorical features can in principle be one-hot or impact encoded, e.g., via `r ref_pkg("mlr3pipelines")` by using a suitable `r ref("mlr3pipelines::PipeOp", "PipeOp")` and wrapping the pipeop + learner in a `r ref("mlr3pipelines::GraphLearner", "GraphLearner")`, the current `EAGGA` implementation does not support such an encoding.
This behavior might change in the near future.
If your use case includes categorical features or multi-class classification tasks, please open an issue so that we are aware of it and can work on implementing proper support with higher priority.

## Building Blocks of EAGGA

As outlined in the paper, the basic building blocks of `EAGGA` are a learner with a hyperparameter search space, a tabular machine learning task, a resampling method and a performance metric.

### Learner and Search Space

The learner must support the specification of feature selection as well as interaction and monotonicity constraints of features.
Currently only `XGBoost` learners (`r ref("mlr3learners::LearnerClassifXgboost", "LearnerClassifXgboost")` or `r ref("mlr3learners::LearnerRegrXgboost")`) are supported.

Feature selection is handled via `r ref_pkg("mlr3pipelines")` making use of `r ref("mlr3pipelines::PipeOpSelect")`.
`EAGGA` further makes use of so-called {feature,interaction,monotonicity}.detectors.
For example, the `r ref("eagga::MonotonicityDetector", "MonotonicityDetector")` is used to detect the sign of a feature if it should be constrained to have a monotone effect on the target.
To apply such a sign correction, the learner must be configured accordingly, this is handled via `r ref("mlr3pipelines::PipeOpColApply")` which will be configured accordingly during optimization.
Finally, to make sure nothing weird happens during optimization, features are always sorted alphabetically in the internal data representation via `r ref("eagga::PipeOpSortFeatures")`.

A suitable learner therefore combines all these pipeops and the learner itself in the form of a `r ref("mlr3pipelines::GraphLearner")` and will look like the following (assuming classification):

```{r}
library(mlr3)
library(eagga)
library(mlr3learners)
library(mlr3pipelines)
library(mlr3misc)
library(data.table)

set.seed(2906)

learner = as_learner(po("colapply") %>>% po("select") %>>% po("sortfeatures") %>>% lrn("classif.xgboost"))
learner$param_set$values$classif.xgboost.booster = "gbtree"
learner$param_set$values$colapply.applicator = function(x) - x
```

Note that we have to set the `"classif.xgboost.booster"` hyperparameter to `"gbtree"`.
Moreover, the function to apply via `r ref("mlr3pipelines::PipeOpColApply", "PipeOpColApply")` must be set to `function(x) - x` (which is responsible for changing the sign of features after having detected the necessity of such a swap via using a monotonicity detector as described above).

Users can customize this pipeline building the graph learner but must adhere to the basic structure (`colapply --> select --> sortfeatures --> [custom user block] --> learner`).

The search space defines the hyperparameter search space that should be optimized over.
An example looks like the following:

```{r}
search_space = ps(
  classif.xgboost.nrounds = p_dbl(lower = log(1), upper = log(500), tags = c("int", "log"),
    trafo = function(x) as.integer(round(exp(x))), default = log(50)),
  classif.xgboost.eta = p_dbl(lower = log(1e-4), upper = log(1), tags = "log",
    trafo = function(x) exp(x), default = log(0.3)),
  classif.xgboost.gamma = p_dbl(lower = log(1e-4), upper = log(7), tags = "log",
    trafo = function(x) exp(x), default = log(1e-4)),
  classif.xgboost.lambda = p_dbl(lower = log(1e-4), upper = log(1000), tags = "log",
    trafo = function(x) exp(x), default = log(1)),
  classif.xgboost.alpha = p_dbl(lower = log(1e-4), upper = log(1000), tags = "log",
    trafo = function(x) exp(x), default = log(1e-4)),
  classif.xgboost.subsample = p_dbl(lower = 0.1, upper = 1, default = 1),
  classif.xgboost.max_depth = p_int(lower = 1, upper = 20, default = 6),
  classif.xgboost.min_child_weight = p_dbl(lower = log(1), upper = log(150), tags = "log",
    trafo = function(x) exp(x), default = log(exp(1))),
  classif.xgboost.colsample_bytree = p_dbl(lower = 0.01, upper = 1, default = 1),
  classif.xgboost.colsample_bylevel = p_dbl(lower = 0.01, upper = 1, default = 1),
  select.selector = p_uty(),  # must be part of the search space
  classif.xgboost.interaction_constraints = p_uty(),  # must be part of the search space
  classif.xgboost.monotone_constraints = p_uty()  # must be part of the search space
)
```

This search space specifies that we tuner over `nrounds`, `eta`, `gamma`, `lambda`, `alpha`, `subsample`, `max_depth`, `min_child_weight`, `colsample_bytree` and `colsample_by_level` which are standard hyperparameters of `XGBoost` (for an explanation and description, see e.g., `?xgboost` or https://xgboost.readthedocs.io/en/stable/parameter.html).
Note that in general it is better to set the upper bound of `nrounds` higher (e.g., around `log(5000)` and the default to `log(500)` but we use less boosting rounds to speed up the following examples.

Additionally, we must specify that we also tune over the feature `selector` and `interaction_constraints` and `monotone_constraints` (we specify these as `r ref("paradox::ParamUty", "ParamUty")` hyperparameters because they are not directly tunable in a standard way.
However, we need to include them into the search space as `eagga` must be able to pass such constraints based on so-called group structures to the learner.

### Task

The task is usually supplied by the user.
Here we will use the following toy task for illustrative purposes:

```{r}
generate_task = function(n) {
  x1 = runif(n, min = 0, max = 3)
  x2 = rnorm(n, sd = 0.1)
  x3 = rnorm(n)
  x4 = runif(n, min = -1, max = 1)
  x5 = rnorm(n)
  y = cos(x1) + 0.1 * x2 + 1.5 * x3 + 0.1 * x4 + x3 * x4
  y = y - mean(y) + rnorm(n, sd = 0.1)
  label = rep("0", n)
  label[y > 0.5] = "1"
  label = as.factor(label)
  dat = data.table(x1 = x1, x2 = x2, x3 = x3, x4 = x4, x5 = x5, label = label)
  task = TaskClassif$new("example", backend = dat, target = "label", positive = "1")
  task
}
task = generate_task(1000)
```

In this task, the label is strongly influenced by the features `"x1"` and `"x3"`, whereas `"x2"` and `"x4"` have smaller influence and `"x5"` is not used at all.
`"x1"` does have a monotone decreasing effect on the probability of predicting a label of `"1"`, whereas `"x2"`, `"x3"` and `"x4"` all have varying linear (monotone increasing) effects on the probability of predicting a label of `"1"`.
Moreover, features `"x3"` and `"x4"` show a simple interaction.

### Resampling

You can use any resampling supported my `r ref_pkg("mlr3")`.
Here we will use three-fold cross-validation:

```{r}
resampling = rsmp("cv", folds = 3)
```

### Performance Measure (and Interpretability Measures)

You can use any performance measure supported by `r ref_pkg("mlr3")`.
Here we will use the classification error:

```{r}
performance_measure = msr("classif.ce")
```

As `EAGGA` jointly optimizes for performance and interpretability, we also need to pass the interpretability measures (`NF`, `NI` and `NNM` in the paper): the relative number of features used by the model, the relative number of (pariwise) interactions of features in the model and the relative number of non-monotone feature effects.

These measures are implemented via so-called proxy measures (proxy because they actually do not work like standard mlr3 measures and do not operate on a `r ref("mlr3::Prediction", "Prediction")` object but rather are always hard coded to a value of zero but updated and computed within the actual optimization process).

For details, see `r ref("eagga::MeasureSelectedFeaturesProxy", "MeasureSelectedFeaturesProxy")`, `r ref("eagga::MeasureSelectedInteractionsProxy", "MeasureSelectedInteractionsProxy")` and `r ref("eagga::MeasureSelectedNonMonotoneProxy", "MeasureSelectedNonMonotoneProxy")`.

Again, note that these measures do not do anything meaningful except for when being used in combination with `eagga`.

```{r}
measures = list(performance_measure, msr("selected_features_proxy"), msr("selected_interactions_proxy"), msr("selected_non_monotone_proxy"))
```

# Tuning with TunerEAGGA

As we have introduced all building blocks, we can now use `EAGGA` to jointly optimize for performance and interpretability.
This works by constructing a `r ref("mlr3tuning::TuningInstanceMultiCrit", "TuningInstanceMultiCrit")` and a `r ref("eagga::TunerEAGGA", "TunerEAGGA")`.

```{r}
instance = TuningInstanceMultiCrit$new(
  task = task,
  learner = learner,
  resampling = resampling, 
  measures = measures,
  terminator = trm("evals", n_evals = 30),
  search_space = search_space
)
```

By setting `terminator = trm("evals", n_evals = 30)` we specify that termination of the tuning process should occur after having evaluated 30 configurations.
This is sufficient for illustrative purposes here but should be set much higher in practice.
Termination can also be specified via other terminators, see, e.g., `?mlr_terminators`

We now construct the tuner.
For everything to smoothly work together, we have to explicitly tell the tuner the pipeop `id` of the learner within the graph learner via `learner_id`.
Moreover, we have to specify the parameter `id` of the interaction constraint and monotonicity constraint hyperparameters via `interaction_id` and `monotone_id`.
We can further specify the population size via `mu` and the offspring size via `lambda`.
Here we set them to `mu = 10` and `lambda = 2` for illustrative purposes (usually they should be set much higher; a good starting point can be `mu = 100` and `lambda = 10`).
Furthermore we can specify `seed_calculate_proxy_measures` to seed the model fitting process of configurations tried during optimization on the task to be able to fully reproduce models resulting in certain `NF`, `NI`, and `NNM` values found during optimization.
For more details, see the section on reconstructing models below.

```{r}
tuner = tnr("eagga",
  learner_id = "classif.xgboost",
  select_id = "select.selector",
  interaction_id = "classif.xgboost.interaction_constraints",
  monotone_id = "classif.xgboost.monotone_constraints",
  mu = 10,
  lambda = 2,
  seed_calculate_proxy_measures = 1
)
```

We can now start the optimization process:

```{r}
tuner$optimize(instance)
```

We can then inspect the Pareto front:

```{r}
measure_ids = c("classif.ce",
  "selected_features_proxy",
  "selected_interactions_proxy",
  "selected_non_monotone_proxy")
front = unique(instance$archive$best()[, measure_ids, with = FALSE])
setorderv(front, cols = "classif.ce")
front
```

We observe that we found diverse models trading off performance and interpretability to varying degree.
We can further inspect the group structure of each model (for more details on the `r ref("eagga::GroupStructure", "GroupStructure")` class, see the technical details section below.

```{r}
instance$archive$best()[8, ]$groupstructure[[1]]$get_groups()
```

We see that in this model, features `"x2"` and `"x5"` are not used (as they are in the first, "unselected" group of features), whereas `"x1"`, `"x3"` and `"x4"` are allowed to interact (as they are in the second group, grouped together).

Moreover,
```{r}
instance$archive$best()[8, ]$groupstructure[[1]]$monotone_features
```
tells us that `"x1"`, `"x3"` and `"x4"` are constrained to have a monotone (increasing) effect on the feature.
But wait, didn't we say that in our toy task, `"x1"` has a monotone decreasing effect on the target?
Yes, but:
As our `r ref("eagga::MonotonicityDetector", "MonotonicityDetector")` within `EAGGA` detected `"x1"` to have a monotone decreasing effect (if enforced) and we were able to swap the sign of the feature itself to then enforce a monotone increasing effect (and in `EAGGA` we only want to differentiate between unconstrained or monotone increasing feature effects):

```{r}
mlr3misc::get_private(tuner)$.monotonicity_detector$get_sign("x1")
```

```{r}
instance$objective$learner$param_set$values$colapply.affect_columns
```

Note: As this process of swapping the sign of features is performed during optimization, you cannot simply use the learner you passed to the instance afterwards to train your learner with a given hyperparameter configuration and group structure.
Instead, you should use the learner within the objective of the instance which was updated in place: `instance$objective$learner`.
To use a hyperparameter configuration and group structure together with this learner, you can then do the following.
Assume we want to use the eighth configuration of the Pareto set, then we can simply specify the hyperparameter values as follows:

```{r}
hpc = instance$archive$best()[8, "x_domain"][[1]][[1]]
```

```{r}
learner = instance$objective$learner
learner$param_set$values = insert_named(learner$param_set$values, hpc)
```

However, as `EAGGA` uses a feedback loop during optimization to update the feature selection, feature interaction and monotonicity constraints based on the actual structures found in the model (tightening the upper bound of the group structure passed to the learner to fit the model and updating this original group structure post hoc), some more additional steps are needed to fully reconstruct a model found during optimization.

In essence, this involves re-creating the feature selection, feature interaction and monotonicity constraints from the original group structure that was used to fit the model (prior to that group structure being updated by the feedback loop):

```{r}
groupstructure_orig = instance$archive$best()[8, "groupstructure_orig"][[1]][[1]]
hpc$select.selector = groupstructure_orig$create_selector()
hpc$classif.xgboost.interaction_constraints = groupstructure_orig$create_interaction_constraints()
hpc$classif.xgboost.monotone_constraints = groupstructure_orig$create_monotonicity_constraints()
learner$param_set$values = insert_named(learner$param_set$values, hpc)
```

To make this easier, the following section describes a more automated way.

# Deciding on a Model and Reconstructing it

Once we have decided on a model (based on a non-dominated hyperparameter configuration and group structure) we prefer, we can "reconstruct" it.
To do so, we use the `r ref("eagga::reconstruct_eagga_model", "reconstruct_eagga_model")` function and pass the tuning instance, the tuner and the uhash of the model we want to "reconstruct" as logged in the archive:

```{r}
uhash = instance$archive$best()$uhash[8]
model = reconstruct_eagga_model(instance, tuner = tuner, model_uhash = uhash)
```

We can then use this model as any other trained learner, for example, if we want to predict on new data:

```{r}
task_test = generate_task(10000)
model$predict(task_test)$score(msr("classif.ce"))
```

In general, note that the performance estimates obtained during optimization via a resampling method can be biased estimates of the performance of the final model, as we have based our decision making process on these performance estimate (this is the in essence the same problem as in single objective hyperparameter optimization and why we should use nested resampling to get an unbiased estimate of the performance of the final model).
Ideally, you do have access to some unseen test data as illustrated above.

# Inspecting Models with the iml Package

As `r ref_pkg("mlr3")` nicely interplays with the `r ref_pkg("iml")` package, we can easily use post-hoc interpretable ML techniques to gain some more insights into a model of our choice.
For example, we can look at ALE plots of each feature:

```{r}
model$predict_type = "prob"
```

```{r}
library(iml)
predictor = Predictor$new(model,
  data = task$data(cols = task$feature_names),
  y = task$data(cols = task$target_names)[[1]])
effect_x2 = FeatureEffect$new(predictor, feature = "x2")
plot(effect_x2)
```

As expected the ALE plot shows us that feature `"x2` has no effect on the target as it cannot be used by the model:
```{r}
model$param_set$values$select.selector
```

Similarly, we can look at other featues:

```{r}
effect_x3 = FeatureEffect$new(predictor, feature = "x3")
plot(effect_x3)
```

We know that feature `"x3"` can be used by the model and is constrained to have a monotone increasing effect on the target - which is also confirmed by the ALE plot.
However, recall that our monotonicity detector during optimization detected that `"x3"` actually should have a monotone decreasing effect on the target and to achieve a monotone increasing effect we switched the sign of the feature.
This is "hidden" in the ALE plot, i..e, it looks as if `"x3"` indeed has a monotone increasing feature effect on predicting the positive class label `"1"` - but the actual monotonicity direction is a decreasing one as we have swapped the sign of the feature (so be careful when interpreting the monotonicity of feature effects, if signs have been swapped during optimization).

```{r}
model$param_set$values$colapply.affect_columns
model$param_set$values$colapply.applicator
```

# Technical Details

This section is work in progress and will explain technical details of the `r ref("eagga::TunerEAGGA", "TunerEAGGA")`, `r ref("eagga::Probs", "Probs")`, `r ref("eagga::InteractionDetector", "InteractionDetector")`, `r ref("eagga::MonotonicityDetector", "MonotonicityDetector")` and `r ref("eagga::GroupStructure", "GroupStructure")` classes.
Note that the feature detector is currently implemented within `r ref("eagga::TunerEAGGA", "TunerEAGGA")` directly and not exposed as a standalone class but this might change in the near future.
The current feature detector is simply based on a `r ref("mlr3filters::FilterInformationGain", "FilterInformationGain")`.

# References
